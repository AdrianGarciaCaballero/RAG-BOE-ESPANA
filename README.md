# ğŸ§  RAG Multimodal "Table-Master" (BOE Edition)

Este proyecto es un **Sistema de RAG (Retrieval-Augmented Generation) Multimodal Avanzado** diseÃ±ado para consultar documentos legales oficiales (como el BOE), entender tablas complejas, analizar imÃ¡genes y responder preguntas sobre datos de recursos humanos.

## ğŸš€ CaracterÃ­sticas Principales

### 1. ğŸ“„ Ingesta de Documentos Inteligente
*   **Semantic Chunking**: Utiliza embeddings para detectar cambios de tema y cortar el texto de forma lÃ³gica, no por caracteres arbitrarios.
*   **Layout Aware (PyMuPDF4LLM)**: Convierte PDFs a Markdown limpio, conservando **Tablas** y estructura visual antes de procesar.
*   **CategorizaciÃ³n por Carpetas**: Detecta la estructura de directorios en `docs/` (ej: `Legal/NÃ³minas`) e inyecta esa categorÃ­a en el contexto semÃ¡ntico.
*   **Ingesta Incremental**: Detecta si un archivo ya existe en la base de datos para evitar re-procesarlo (ahorro de tiempo y costes).

### 2. ğŸ‘ï¸ Capacidades Multimodales (Vision)
*   **AnÃ¡lisis Visual de Documentos**: Si el documento contiene imÃ¡genes o grÃ¡ficos, el sistema las busca mediante descripciÃ³n semÃ¡ntica.
*   **Visual Filter (LLaVA)**: Un nodo agente utiliza el modelo de visiÃ³n `llava` para "mirar" la imagen candidata y verificar si contiene la respuesta exacta (ej: leer un dato numÃ©rico de una tabla escaneada).
*   **Query-by-Image**: Â¡Nuevo! Puedes subir una foto (nÃ³mina, contrato) al chat y preguntar sobre ella. El sistema la analiza con LLaVA y usa esa informaciÃ³n para buscar en la base de datos.

### 3. ğŸ§  Router & Agentes ("Cerebro")
El sistema no busca ciegamente. Tiene un **Router Inteligente** que clasifica tu pregunta:
*   **Ruta "RAG"**: Si preguntas sobre leyes o documentos ("Â¿QuÃ© dice el artÃ­culo 5?"), busca en los PDFs.
*   **Ruta "DATA"**: Si preguntas sobre empleados ("Â¿CuÃ¡ntas vacaciones le quedan a Adrian?"), consulta una **base de datos estructurada** (`employees.csv`) usando Pandas.

### 4. ğŸ” TÃ©cnicas de RecuperaciÃ³n Avanzadas
El sistema implementa 4 tÃ©cnicas sofisticadas para asegurar que siempre se encuentra el documento mÃ¡s relevante:
*   **RecuperaciÃ³n HÃ­brida (BM25 + Vector)**: Combina la bÃºsqueda semÃ¡ntica (vectores) con la bÃºsqueda por palabras clave (BM25) para capturar tanto el sentido conceptual como tÃ©rminos exactos (ej. nÃºmero de artÃ­culo).
*   **Cross-Encoder Re-ranking**: Un modelo dedicado (`BAAI/bge-reranker`) re-examina los mejores candidatos de la bÃºsqueda inicial y los reordena meticulosamente por relevancia.
*   **Reciprocal Rank Fusion (RRF)**: Algoritmo que fusiona los resultados de BM25 y Vectores de forma justa y ponderada.
*   **Routing SemÃ¡ntico**: Clasificadores automÃ¡ticos dirigen la pregunta al subsistema experto adecuado (Data vs Documentos).
---

## ğŸ› ï¸ Requisitos e InstalaciÃ³n

### 1. Entorno Python
```bash
# Crear entorno (recomendado)
conda create -n Tartanga python=3.11
conda activate Tartanga

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Modelos Locales (Ollama)
Necesitas tener [Ollama](https://ollama.com/) instalado y descargados los siguientes modelos:
```bash
ollama pull llama3       # Cerebro de texto
ollama pull llava        # VisiÃ³n multimodal
```

### 3. Base de datos
No necesitas instalar nada extra. El proyecto usa **ChromaDB** en modo local (carpeta `chroma_db`).

---

## â–¶ï¸ Uso del Sistema

### 1. Ingesta de Datos (PreparaciÃ³n)
Antes de chatear, el sistema necesita aprender. Coloca tus PDFs en la carpeta `docs/` (puedes crear subcarpetas).

```bash
# Ejecutar ingesta inteligente
python ingest_multimodal.py
```
*Este proceso leerÃ¡ tus PDFs, extraerÃ¡ tablas y texto, crearÃ¡ chunks semÃ¡nticos y los guardarÃ¡ en ChromaDB.*

### 2. Iniciar el Backend (Cerebro)
En una terminal:
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```
*Si ves "ğŸ§  RAG Table-Master Iniciado", todo estÃ¡ bien.*

### 3. Iniciar el Frontend (Chat)
En **otra** terminal:
```bash
streamlit run frontend.py
```
Se abrirÃ¡ tu navegador en `http://localhost:8501`.

---

## ğŸ§ª Ejemplos de Pruebas

### ğŸ” Preguntas RAG (Documentos)
> *"Â¿QuÃ© dice el BOE sobre las bajas por maternidad?"*
> *"Resume el artÃ­culo 14 del convenio."*

### ğŸ“Š Preguntas DATA (RRHH)
> *"Â¿CuÃ¡ntos dÃ­as de vacaciones le quedan a Adrian?"*
> *"Â¿QuiÃ©n es el HR Manager?"*
*(El sistema detectarÃ¡ que es un dato personal y consultarÃ¡ el CSV automÃ¡ticamente)*

### ğŸ“· Preguntas con Imagen
1. Abre el desplegable **"ğŸ“· Adjuntar imagen"** en el chat.
2. Sube una foto de una tabla o documento.
3. Pregunta: *"Â¿Es correcta esta nÃ³mina segÃºn el convenio?"*.
*(El sistema "leerÃ¡" tu foto y cruzarÃ¡ la informaciÃ³n con los PDFs del BOE)*

---

## ğŸ“ˆ EvaluaciÃ³n del Sistema (RÃºbrica SAA)

El proyecto incluye un sistema completo de evaluaciÃ³n cuantitativa para medir la calidad del RAG.

### 1. EvaluaciÃ³n del Buscador (Retrieval)
Script: `eval_retrieval.py`
*   **MÃ©tricas**: Hit Rate @ K y MRR (Mean Reciprocal Rank).
*   **Comparativa**: Genera automÃ¡ticamente una tabla comparando configuraciones (ej. Top-3 vs Top-10).
*   **EjecuciÃ³n**:
    ```bash
    python eval_retrieval.py
    ```

### 2. EvaluaciÃ³n de GeneraciÃ³n (RAGAS)
Script: `eval_ragas.py`
*   **MÃ©tricas**: Faithfulness (Fidelidad) y Answer Relevancy.
*   **Juez**: Utiliza LLM local (Ollama) para evaluar las respuestas generadas sin coste de API.
*   **Dataset**: Utiliza `data/golden_dataset.json` como "Golden Set" de verdad terreno.
*   **EjecuciÃ³n**:
    ```bash
    python eval_ragas.py
    ```

---

## ğŸ“‚ Estructura de Proyecto

*   `main.py`: **API Backend**. Contiene el grafo LangGraph, Nodos (Router, Retriever, Vision), y endpoints.
*   `frontend.py`: **Interfaz Streamlit**. Chatbot con soporte de subida de archivos e imÃ¡genes.
*   `ingest_multimodal.py`: **Script de Ingesta Avanzada**. PyMuPDF4LLM + Semantic Chunking.
*   `tools_data.py`: Herramienta para consultar `data/employees.csv`.
*   `eval_retrieval.py`: **Script de ValidaciÃ³n SAA**. Mide Hit Rate y MRR.
*   `eval_ragas.py`: **Script de ValidaciÃ³n SAA**. Mide mÃ©tricas RAGAS.
*   `data/`: Carpeta para bases de datos estructuradas (CSV) y **Golden Dataset**.
*   `docs/`: Carpeta donde dejas tus PDFs.
*   `chroma_db/`: Base de datos vectorial (generada automÃ¡ticamente).

---