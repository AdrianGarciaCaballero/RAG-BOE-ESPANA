# ğŸ§  RAG Multimodal "Table-Master" (BOE Edition)

Este proyecto es un **Sistema de RAG (Retrieval-Augmented Generation) Multimodal Avanzado** diseÃ±ado para consultar documentos legales oficiales (como el BOE), entender tablas complejas, analizar imÃ¡genes y responder preguntas sobre datos de recursos humanos.

## ğŸš€ CaracterÃ­sticas Principales

### 1. ğŸ“„ Ingesta de Documentos Inteligente
*   **Semantic Chunking**: Utiliza embeddings para detectar cambios de tema y cortar el texto de forma lÃ³gica, no por caracteres arbitrarios.
*   **Layout Aware (PyMuPDF4LLM)**: Convierte PDFs a Markdown limpio, conservando **Tablas** y estructura visual antes de procesar.
*   **CategorizaciÃ³n por Carpetas**: Detecta la estructura de directorios en `docs/` (ej: `Legal/NÃ³minas`) e inyecta esa categorÃ­a en el contexto semÃ¡ntico.
*   **Ingesta Incremental**: Detecta si un archivo ya existe en la base de datos para evitar re-procesarlo (ahorro de tiempo y costes).

### 2. ğŸ‘ï¸ Capacidades Multimodales (Vision)
*   **AnÃ¡lisis Visual de Documentos**: Si el documento contiene imÃ¡genes o grÃ¡ficos, el sistema las busca mediante descripciÃ³n semÃ¡ntica.
*   **Visual Filter (LLaVA)**: Un nodo agente utiliza el modelo de visiÃ³n `llava` para "mirar" la imagen candidata y verificar si contiene la respuesta exacta (ej: leer un dato numÃ©rico de una tabla escaneada).
*   **Base de Conocimiento Visual**: El sistema utiliza un repositorio de imÃ¡genes pre-procesadas y etiquetadas (en `static/labeled_images`) que se recuperan y adjuntan automÃ¡ticamente a la respuesta cuando son relevantes para la consulta del usuario.
*   **Query-by-Image**: Â¡Nuevo! Puedes subir una foto (nÃ³mina, contrato) al chat y preguntar sobre ella. El sistema la analiza con LLaVA y usa esa informaciÃ³n para buscar en la base de datos.

### 3. ğŸ§  Router & Agentes ("Cerebro")
El sistema no busca ciegamente. Tiene un **Router Inteligente** que clasifica tu pregunta:
*   **Ruta "RAG"**: Si preguntas sobre leyes o documentos ("Â¿QuÃ© dice el artÃ­culo 5?"), busca en los PDFs.
*   **Ruta "DATA"**: Si preguntas sobre empleados ("Â¿CuÃ¡ntas vacaciones le quedan a Adrian?"), consulta una **base de datos estructurada** (`employees.csv`) usando Pandas.

### 4. ğŸ” TÃ©cnicas de RecuperaciÃ³n Avanzadas
El sistema implementa 4 tÃ©cnicas sofisticadas para asegurar que siempre se encuentra el documento mÃ¡s relevante:
*   **RecuperaciÃ³n HÃ­brida (BM25 + Vector)**: Combina la bÃºsqueda semÃ¡ntica (vectores) con la bÃºsqueda por palabras clave (BM25) para capturar tanto el sentido conceptual como tÃ©rminos exactos (ej. nÃºmero de artÃ­culo).
*   **Cross-Encoder Re-ranking**: Un modelo dedicado (`BAAI/bge-reranker`) re-examina los mejores candidatos de la bÃºsqueda inicial y los reordena meticulosamente por relevancia.
*   **Reciprocal Rank Fusion (RRF)**: Algoritmo que fusiona los resultados de BM25 y Vectores de forma justa y ponderada.
*   **Routing SemÃ¡ntico**: Clasificadores automÃ¡ticos dirigen la pregunta al subsistema experto adecuado (Data vs Documentos).
---

## ğŸ› ï¸ Requisitos e InstalaciÃ³n

### 1. Entorno Python
```bash
# Crear entorno (recomendado)
conda create -n Tartanga python=3.11
conda activate Tartanga

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Modelos Locales (Ollama)
Necesitas tener [Ollama](https://ollama.com/) instalado y descargados los siguientes modelos:
```bash
ollama pull llama3       # Cerebro de texto
ollama pull llava        # VisiÃ³n multimodal
```

### 3. Base de datos
No necesitas instalar nada extra. El proyecto usa **ChromaDB** en modo local (carpeta `chroma_db`).

---

## â–¶ï¸ Uso del Sistema

### 1. Ingesta de Datos (PreparaciÃ³n)
Antes de chatear, el sistema necesita aprender. Coloca tus PDFs en la carpeta `docs/` (puedes crear subcarpetas).

```bash
# Ejecutar ingesta inteligente
python ingest_multimodal.py
```
*Este proceso leerÃ¡ tus PDFs, extraerÃ¡ tablas y texto, crearÃ¡ chunks semÃ¡nticos y los guardarÃ¡ en ChromaDB.*

### 2. Iniciar el Backend (Cerebro)
En una terminal:
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```
*Si ves "ğŸ§  RAG Table-Master Iniciado", todo estÃ¡ bien.*

### 3. Iniciar el Frontend (Chat)
En **otra** terminal:
```bash
streamlit run frontend.py
```
Se abrirÃ¡ tu navegador en `http://localhost:8501`.

### 4. Iniciar el Bot de Telegram
En **otra** terminal:
```bash
python src/bot/telegram_bot.py
```
*AsegÃºrate de tener un `TELEGRAM_TOKEN` vÃ¡lido en tu archivo `.env` o variables de entorno.*

---

## ğŸ§ª Ejemplos de Pruebas

### ğŸ” Preguntas RAG (Documentos)
> *"Â¿QuÃ© dice el BOE sobre las bajas por maternidad?"*
> *"Resume el artÃ­culo 14 del convenio."*

### ğŸ“Š Preguntas DATA (RRHH)
> *"Â¿CuÃ¡ntos dÃ­as de vacaciones le quedan a Adrian?"*
> *"Â¿QuiÃ©n es el HR Manager?"*
*(El sistema detectarÃ¡ que es un dato personal y consultarÃ¡ el CSV automÃ¡ticamente)*

### ğŸ“· Preguntas con Imagen
1. Abre el desplegable **"ğŸ“· Adjuntar imagen"** en el chat.
2. Sube una foto de una tabla o documento.
3. Pregunta: *"Â¿Es correcta esta nÃ³mina segÃºn el convenio?"*.
*(El sistema "leerÃ¡" tu foto y cruzarÃ¡ la informaciÃ³n con los PDFs del BOE)*

---

## ğŸ“ˆ EvaluaciÃ³n del Sistema (RÃºbrica SAA)

El proyecto incluye un sistema completo de evaluaciÃ³n cuantitativa para medir la calidad del RAG.

### 1. EvaluaciÃ³n del Buscador (Retrieval)
Script: `eval_retrieval.py`
*   **MÃ©tricas**: Hit Rate @ K y MRR (Mean Reciprocal Rank).
*   **Resultados Actuales (v1.5)**:
    | ConfiguraciÃ³n | Hit Rate | MRR |
    | :--- | :--- | :--- |
    | **Top-3 (Strict)** | **0.80** | **0.70** |
    | **Top-10 (Broad)** | **1.00** | **0.74** |
*   **EjecuciÃ³n**:
    ```bash
    python eval_retrieval.py
    ```

### 2. EvaluaciÃ³n de GeneraciÃ³n (RAGAS)
Script: `eval_ragas.py`
*   **MÃ©tricas**: Faithfulness (Fidelidad) y Answer Relevancy.
*   **Resultados Preliminares (Sample n=3)**:
    | MÃ©trica | PuntuaciÃ³n | DescripciÃ³n |
    | :--- | :--- | :--- |
    | **Faithfulness** | **0.88** | PrecisiÃ³n factual respecto al contexto |
    | **Answer Relevancy** | **0.71** | Relevancia de la respuesta a la pregunta |
*   **Juez**: Utiliza LLM local (Ollama) para evaluar las respuestas generadas sin coste de API.
*   **Dataset**: Utiliza `data/golden_dataset.json` como "Golden Set" de verdad terreno.
*   **EjecuciÃ³n**:
    ```bash
    python eval_ragas.py
    ```

---

## ğŸ“‚ Estructura de Proyecto

El cÃ³digo ha sido reorganizado en una arquitectura modular dentro de `src/` para escalabilidad y limpieza.

```plaintext
ğŸ“¦ RAG-BOE-ESPANA
 â”£ ğŸ“‚ src                    # CÃ³digo Fuente Principal
 â”ƒ â”£ ğŸ“‚ api                  # Backend FastAPI
 â”ƒ â”ƒ â”£ ğŸ“œ main.py            # ğŸ§  API REST & Grafo LangChain
 â”ƒ â”ƒ â”— ğŸ“œ retrieval_engine.py# ğŸ” Motor de bÃºsqueda (BM25 + Chroma)
 â”ƒ â”£ ğŸ“‚ frontend             # Interfaz de Usuario
 â”ƒ â”ƒ â”— ğŸ“œ frontend.py        # ğŸ¨ App Streamlit
 â”ƒ â”£ ğŸ“‚ ingestion            # ETL & Procesamiento
 â”ƒ â”ƒ â”£ ğŸ“œ ingest.py          # Script principal de ingesta PDF
 â”ƒ â”ƒ â”£ ğŸ“œ ingest_csv.py      # Ingesta de Datos Estructurados
 â”ƒ â”ƒ â”£ ğŸ“œ ingest_images.py   # Ingesta de ImÃ¡genes
 â”ƒ â”ƒ â”— ğŸ“œ ingest_multimodal.py # Orquestador avanzado
 â”ƒ â”£ ğŸ“‚ evaluation           # MÃ©tricas & Calidad
 â”ƒ â”ƒ â”£ ğŸ“œ eval_ragas.py      # ValidaciÃ³n RAGAS (LLM-as-Judge)
 â”ƒ â”ƒ â”— ğŸ“œ eval_retrieval.py  # ValidaciÃ³n Retrieval (Hit Rate/MRR)
 â”ƒ â”£ ğŸ“‚ bot                  # Integraciones
 â”ƒ â”ƒ â”— ğŸ“œ telegram_bot.py    # ğŸ¤– Bot de Telegram
 â”ƒ â”— ğŸ“‚ utils                # Utilidades
 â”ƒ   â”— ğŸ“œ tools_data.py      # Herramientas de Pandas/Datos
 â”£ ğŸ“‚ chroma_db              # ğŸ’¾ Base de datos Vectorial
 â”£ ğŸ“‚ data                   # ğŸ“Š Datos CSV y Golden Datasets
 â”£ ğŸ“‚ docs                   # ğŸ“„ Documentos PDF de entrada
 â”£ ğŸ“‚ static/labeled_images  # ğŸ–¼ï¸ ImÃ¡genes extraÃ­das etiquetadas
 â”— ğŸ“œ requirements.txt       # Dependencias
```

### ğŸ“ GuÃ­a RÃ¡pida de EjecuciÃ³n (Nuevas Rutas)
Debido a la reestructuraciÃ³n, ejecuta los scripts desde la raÃ­z del proyecto asi:

| Componente | Comando Nuevo |
| :--- | :--- |
| **Backend API** | `python src/api/main.py` |
| **Frontend** | `streamlit run src/frontend/frontend.py` |
| **Ingesta** | `python src/ingestion/ingest.py` |
| **Bot Telegram** | `python src/bot/telegram_bot.py` |
| **EvaluaciÃ³n** | `python src/evaluation/eval_ragas.py` |

---